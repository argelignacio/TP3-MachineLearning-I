{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\igna-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importacion general de librerias y de visualizacion (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import numpy as np\n",
    "import random as rd\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('stopwords')\n",
    "\n",
    "plt.style.use('default') # haciendo los graficos un poco mas bonitos en matplotlib\n",
    "#plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "sns.set(style=\"whitegrid\") # seteando tipo de grid en seaborn\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puntos Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = pd.read_csv('train_identity.csv')\n",
    "transaction = pd.read_csv('train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeado = identity.merge(transaction, left_on='TransactionID', right_on='TransactionID',\n",
    "          how = 'right')\n",
    "mergeado.drop(['TransactionID'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliteo el 20% con el delta tiempo mayor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lenght = int(144233*0.2)\n",
    "mergeado.sort_values(by = \"TransactionDT\")\n",
    "train_lenght = (144233- test_lenght)\n",
    "train = mergeado.iloc[0:train_lenght ,:]\n",
    "test = mergeado.iloc[(144233- test_lenght):144233,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodeo el train set y el validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean encoding en id_30 y OHE en las demas categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"id_30\"].fillna(\"Desconocido\",inplace =True)\n",
    "mean_encoder_id_30 = train.groupby(['id_30'])['isFraud'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"id_31\"].fillna(\"Desconocido\",inplace =True)\n",
    "vec = CountVectorizer().fit(train[\"id_31\"])\n",
    "bag_of_words = vec.transform(train[\"id_31\"])\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "filtro31 = list(filter(lambda c: c[0].isalpha() and c[1] > 2000, words_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"DeviceInfo\"].fillna(\"Desconocido\",inplace =True)\n",
    "vec = CountVectorizer().fit(train[\"DeviceInfo\"])\n",
    "bag_of_words = vec.transform(train[\"DeviceInfo\"])\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "filtroDI = list(filter(lambda c: c[0].isalpha() and c[1] > 2000, words_freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector(x, vec):\n",
    "  for item in vec:\n",
    "    if x.find(item[0]):\n",
    "      return item[0]\n",
    "    else:\n",
    "      return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_30'] =  train['id_30'].map(mean_encoder_id_30)\n",
    "train['id_31'] = train['id_31'].map(lambda x: selector(x, filtro31))\n",
    "train['DeviceInfo'] = train['DeviceInfo'].map(lambda x: selector(x, filtroDI))\n",
    "\n",
    "X_cat = ['ProductCD','card4','id_34','id_15','id_23','id_31','DeviceType','DeviceInfo' ,'card6','P_emaildomain','R_emaildomain','M1','M2','M3','M4','M5','M6','M7','M8','M9']\n",
    "\n",
    "cont_df = train.drop(X_cat,axis =1)\n",
    "cont_df['id_12'] = cont_df['id_12'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_13'] = cont_df['id_13'].astype(float).fillna(cont_df['id_13'].mean()) \n",
    "cont_df['id_16'] = cont_df['id_16'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_27'] = cont_df['id_27'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_28'] = cont_df['id_28'].replace('Found',1).replace('New',0).astype(float)\n",
    "cont_df['id_29'] = cont_df['id_29'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_13'] = cont_df['id_13'].astype(float).fillna(cont_df['id_13'].mean()) \n",
    "cont_df['id_33'] = cont_df['id_33'].astype(str).map(lambda x : 'nan' if x.find('nan') != -1 else\n",
    "                                               int(x.split('x')[0])*int(x.split('x')[1])).astype(float)\n",
    "media = cont_df['id_33'].mean()\n",
    "cont_df['id_33'] = cont_df['id_33'] /media\n",
    "cont_df['id_35'] = cont_df['id_35'].replace('T',1).replace('F',0).astype(float)\n",
    "cont_df['id_36'] = cont_df['id_36'].replace('T',1).replace('F',0).astype(float)\n",
    "cont_df['id_37'] = cont_df['id_37'].replace('T',1).replace('F',0).astype(float)\n",
    "cont_df['id_38'] = cont_df['id_38'].replace('T',1).replace('F',0).astype(float)\n",
    "\n",
    "cont_df.apply(lambda x: x.fillna(x.mean(),inplace = True)) \n",
    "cont_df.apply(lambda x: x.fillna(0,inplace = True)) \n",
    "cat_df = train[X_cat].fillna('Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = []\n",
    "for columna in X_cat:    \n",
    "    ohe = OneHotEncoder(handle_unknown = 'ignore')  # drop='first'\n",
    "    encoded_data = (ohe.fit_transform(cat_df[[columna]].astype(str)).todense().astype(int))\n",
    "    encoders.append(ohe)\n",
    "    encoded_data = pd.DataFrame(encoded_data, index = cont_df.index ).add_prefix(columna[0:8])\n",
    "    cont_df = pd.concat([cont_df, encoded_data], axis=1)\n",
    "train = cont_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"id_30\"].fillna(\"Desconocido\",inplace =True)\n",
    "test[\"id_31\"].fillna(\"Desconocido\",inplace =True)\n",
    "test[\"DeviceInfo\"].fillna(\"Desconocido\",inplace =True)\n",
    "                          \n",
    "test['id_30'] =  test['id_30'].map(mean_encoder_id_30)\n",
    "test['id_31'] = test['id_31'].map(lambda x: selector(x, filtro31))\n",
    "test['DeviceInfo'] = test['DeviceInfo'].map(lambda x: selector(x, filtroDI))\n",
    "\n",
    "X_cat = ['ProductCD','card4','id_34','id_15','id_23','id_31','DeviceType','DeviceInfo' ,'card6','P_emaildomain','R_emaildomain','M1','M2','M3','M4','M5','M6','M7','M8','M9']\n",
    "\n",
    "cont_df = test.drop(X_cat,axis =1)\n",
    "cont_df['id_12'] = cont_df['id_12'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_13'] = cont_df['id_13'].astype(float).fillna(cont_df['id_13'].mean()) \n",
    "cont_df['id_16'] = cont_df['id_16'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_27'] = cont_df['id_27'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_28'] = cont_df['id_28'].replace('Found',1).replace('New',0).astype(float)\n",
    "cont_df['id_29'] = cont_df['id_29'].replace('Found',1).replace('NotFound',0).astype(float)\n",
    "cont_df['id_13'] = cont_df['id_13'].astype(float).fillna(cont_df['id_13'].mean()) \n",
    "cont_df['id_33'] = cont_df['id_33'].astype(str).map(lambda x : 'nan' if x.find('nan') != -1 else\n",
    "                                               int(x.split('x')[0])*int(x.split('x')[1])).astype(float)\n",
    "media = cont_df['id_33'].mean()\n",
    "cont_df['id_33'] = cont_df['id_33'] /media\n",
    "cont_df['id_35'] = cont_df['id_35'].replace('T',1).replace('F',0).astype(float)\n",
    "cont_df['id_36'] = cont_df['id_36'].replace('T',1).replace('F',0).astype(float)\n",
    "cont_df['id_37'] = cont_df['id_37'].replace('T',1).replace('F',0).astype(float)\n",
    "cont_df['id_38'] = cont_df['id_38'].replace('T',1).replace('F',0).astype(float)\n",
    "\n",
    "cont_df.apply(lambda x: x.fillna(x.mean(),inplace = True)) \n",
    "cont_df.apply(lambda x: x.fillna(0,inplace = True)) \n",
    "cat_df = test[X_cat].fillna('Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0 \n",
    "for columna in X_cat:  \n",
    "    encoded_data = (encoders[cont].transform(cat_df[[columna]].astype(str)).todense().astype(int))\n",
    "    encoded_data = pd.DataFrame(encoded_data, index = cont_df.index ).add_prefix(columna[0:8])\n",
    "    cont_df = pd.concat([cont_df, encoded_data], axis=1)\n",
    "    cont += 1\n",
    "test = cont_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['isFraud'], axis=1)\n",
    "y_train = train.loc[:, 'isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= test.drop(['isFraud'], axis=1)\n",
    "y_test = test.loc[:, 'isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_04</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>id_10</th>\n",
       "      <th>...</th>\n",
       "      <th>M62</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M72</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>136,512.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>136,512.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>136,512.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>136,512.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>70,787.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115382</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>82,511.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115383</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>136,512.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115384</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>136,512.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115385</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>194,676.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115386</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>31,544.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-39.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115387 rows × 593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id_01                id_02                id_03  \\\n",
       "0                     -8.21           136,512.62                 0.08   \n",
       "1                     -8.21           136,512.62                 0.08   \n",
       "2                     -8.21           136,512.62                 0.08   \n",
       "3                     -8.21           136,512.62                 0.08   \n",
       "4                      0.00            70,787.00                 0.08   \n",
       "...                     ...                  ...                  ...   \n",
       "115382                -5.00            82,511.00                 0.08   \n",
       "115383                -8.21           136,512.62                 0.08   \n",
       "115384                -8.21           136,512.62                 0.08   \n",
       "115385                -5.00           194,676.00                 0.08   \n",
       "115386                -5.00            31,544.00                 0.00   \n",
       "\n",
       "                      id_04                id_05                id_06  \\\n",
       "0                     -0.06                 1.94                -5.92   \n",
       "1                     -0.06                 1.94                -5.92   \n",
       "2                     -0.06                 1.94                -5.92   \n",
       "3                     -0.06                 1.94                -5.92   \n",
       "4                     -0.06                 1.94                -5.92   \n",
       "...                     ...                  ...                  ...   \n",
       "115382                -0.06                 0.00                 0.00   \n",
       "115383                -0.06                 1.94                -5.92   \n",
       "115384                -0.06                 1.94                -5.92   \n",
       "115385                -0.06                 0.00                 0.00   \n",
       "115386                 0.00                 1.00                -8.00   \n",
       "\n",
       "                      id_07                id_08                id_09  \\\n",
       "0                     14.28               -39.95                 0.13   \n",
       "1                     14.28               -39.95                 0.13   \n",
       "2                     14.28               -39.95                 0.13   \n",
       "3                     14.28               -39.95                 0.13   \n",
       "4                     14.28               -39.95                 0.13   \n",
       "...                     ...                  ...                  ...   \n",
       "115382                14.28               -39.95                 0.13   \n",
       "115383                14.28               -39.95                 0.13   \n",
       "115384                14.28               -39.95                 0.13   \n",
       "115385                14.28               -39.95                 0.13   \n",
       "115386                14.28               -39.95                 0.00   \n",
       "\n",
       "                      id_10  ...  M62  M70  M71  M72  M80  M81  M82  M90  M91  \\\n",
       "0                     -0.34  ...    1    0    1    0    0    1    0    0    1   \n",
       "1                     -0.34  ...    1    0    1    0    0    1    0    0    1   \n",
       "2                     -0.34  ...    0    1    0    0    1    0    0    1    0   \n",
       "3                     -0.34  ...    0    0    1    0    0    1    0    0    1   \n",
       "4                     -0.34  ...    0    0    1    0    0    1    0    0    1   \n",
       "...                     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "115382                -0.34  ...    0    0    1    0    0    1    0    0    1   \n",
       "115383                -0.34  ...    1    1    0    0    1    0    0    1    0   \n",
       "115384                -0.34  ...    1    0    1    0    0    1    0    0    1   \n",
       "115385                -0.34  ...    0    0    1    0    0    1    0    0    1   \n",
       "115386                 0.00  ...    0    0    1    0    0    1    0    0    1   \n",
       "\n",
       "        M92  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "115382    0  \n",
       "115383    0  \n",
       "115384    0  \n",
       "115385    0  \n",
       "115386    0  \n",
       "\n",
       "[115387 rows x 593 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizo data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='tanh', input_dim=593))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer= opt, metrics=[keras.metrics.AUC(\n",
    "    num_thresholds=20,\n",
    "    curve=\"ROC\",\n",
    "    summation_method=\"interpolation\",\n",
    "    name=None,\n",
    "    dtype=None,\n",
    "    thresholds=None,\n",
    "    multi_label=False,\n",
    "    num_labels=None,\n",
    "    label_weights=None,\n",
    "    from_logits=False,\n",
    ")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 100)               59400     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,601\n",
      "Trainable params: 69,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "113/113 [==============================] - 2s 10ms/step - loss: 0.1589 - auc_4: 0.7423\n",
      "Epoch 2/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0713 - auc_4: 0.8138\n",
      "Epoch 3/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0628 - auc_4: 0.8391\n",
      "Epoch 4/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0577 - auc_4: 0.8514\n",
      "Epoch 5/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0535 - auc_4: 0.8632\n",
      "Epoch 6/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0499 - auc_4: 0.8789\n",
      "Epoch 7/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0464 - auc_4: 0.8903\n",
      "Epoch 8/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0440 - auc_4: 0.8940\n",
      "Epoch 9/50\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0410 - auc_4: 0.9036\n",
      "Epoch 10/50\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0376 - auc_4: 0.9127\n",
      "Epoch 11/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0353 - auc_4: 0.9207\n",
      "Epoch 12/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0336 - auc_4: 0.9294\n",
      "Epoch 13/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0317 - auc_4: 0.9290\n",
      "Epoch 14/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0296 - auc_4: 0.9352\n",
      "Epoch 15/50\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0280 - auc_4: 0.9411\n",
      "Epoch 16/50\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0276 - auc_4: 0.9434\n",
      "Epoch 17/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0255 - auc_4: 0.9476\n",
      "Epoch 18/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0245 - auc_4: 0.9503\n",
      "Epoch 19/50\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0231 - auc_4: 0.9545\n",
      "Epoch 20/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0217 - auc_4: 0.9563\n",
      "Epoch 21/50\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0205 - auc_4: 0.9583\n",
      "Epoch 22/50\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0204 - auc_4: 0.9594\n",
      "Epoch 23/50\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0187 - auc_4: 0.9657\n",
      "Epoch 24/50\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0179 - auc_4: 0.9639\n",
      "Epoch 25/50\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0172 - auc_4: 0.9680\n",
      "Epoch 26/50\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0167 - auc_4: 0.9675\n",
      "Epoch 27/50\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.0157 - auc_4: 0.9732\n",
      "Epoch 28/50\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 0.0155 - auc_4: 0.9693: 1s - loss\n",
      "Epoch 29/50\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0145 - auc_4: 0.9755\n",
      "Epoch 30/50\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0141 - auc_4: 0.9759\n",
      "Epoch 31/50\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0134 - auc_4: 0.9742\n",
      "Epoch 32/50\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0141 - auc_4: 0.9758\n",
      "Epoch 33/50\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0141 - auc_4: 0.9767\n",
      "Epoch 34/50\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.0140 - auc_4: 0.9779\n",
      "Epoch 35/50\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0127 - auc_4: 0.9795\n",
      "Epoch 36/50\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0120 - auc_4: 0.9816\n",
      "Epoch 37/50\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0112 - auc_4: 0.9811\n",
      "Epoch 38/50\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 0.0108 - auc_4: 0.9839: 1s -\n",
      "Epoch 39/50\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 0.0100 - auc_4: 0.9824\n",
      "Epoch 40/50\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0104 - auc_4: 0.9821\n",
      "Epoch 41/50\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0093 - auc_4: 0.9849\n",
      "Epoch 42/50\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0091 - auc_4: 0.9864\n",
      "Epoch 43/50\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0091 - auc_4: 0.9855\n",
      "Epoch 44/50\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.0086 - auc_4: 0.9866\n",
      "Epoch 45/50\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0082 - auc_4: 0.9886\n",
      "Epoch 46/50\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.0088 - auc_4: 0.9862: 1\n",
      "Epoch 47/50\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0105 - auc_4: 0.9845\n",
      "Epoch 48/50\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0105 - auc_4: 0.9837\n",
      "Epoch 49/50\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0093 - auc_4: 0.9866\n",
      "Epoch 50/50\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.0077 - auc_4: 0.9883: 0s - loss: 0.0074 - auc_4\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y_train.values , epochs=50, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledTest = sc.transform(X_test)\n",
    "preds = model.predict(scaledTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625183295904044"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(np.asarray(y_test).flatten(), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar features XGBoost y Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importancias XGBoost<img src=\"xgboostimport.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importancias Logistic Regresion <img src=\"regresimport.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece como que toman diferentes importancias en los features entre ambos modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
